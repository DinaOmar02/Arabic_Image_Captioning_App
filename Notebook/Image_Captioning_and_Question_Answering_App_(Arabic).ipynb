{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGD30kZov8D0"
      },
      "source": [
        "# Install Required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFBLsBB7Zepu"
      },
      "outputs": [],
      "source": [
        "# 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\n",
        "# from huggingface_hub import login\n",
        "# login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbUw1J56drt6",
        "outputId": "4cc68f72-0356-4d81-88ef-9ce2bed7c2f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install gtts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h1Tj9uod0f5",
        "outputId": "c1cbbd8c-083e-4c07-b98e-a6b5cd935c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.44.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.6.8)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.31.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio) (0.38.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0kF7VeMZh_v"
      },
      "outputs": [],
      "source": [
        "# !pip install diffusers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qLANfaTwAbu"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikOU2OspdU1_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import requests\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration , AutoModelForCausalLM, AutoTokenizer, pipeline , AutoProcessor , AutoModelForPreTraining ,BlipProcessor, BlipForQuestionAnswering\n",
        "from gtts import gTTS\n",
        "import gradio as gr\n",
        "#from diffusers import StableDiffusion3Pipeline\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "from transformers import AutoTokenizer, MarianMTModel\n",
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjzrFsy_wC1-"
      },
      "source": [
        "# Create APP Classses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jof90lmGZXy1"
      },
      "outputs": [],
      "source": [
        "class TranslateText:\n",
        "    def __init__(self):\n",
        "        # Intialize model and Tokenizer\n",
        "        self.model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
        "        self.tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
        "\n",
        "    def get_translation(self,text,ar_en=False,en_ar=False):\n",
        "        if ar_en:\n",
        "            ar_text = text\n",
        "            self.tokenizer.src_lang = \"ar\"\n",
        "            encoded_text = self.tokenizer(ar_text, return_tensors=\"pt\")\n",
        "            generated_tokens = self.model.generate(**encoded_text, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n",
        "            return self.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "        else:\n",
        "            en_text = text\n",
        "            self.tokenizer.src_lang = \"en\"\n",
        "            encoded_text = self.tokenizer(en_text, return_tensors=\"pt\")\n",
        "            generated_tokens = self.model.generate(**encoded_text, forced_bos_token_id=tokenizer.get_lang_id(\"ar\"))\n",
        "            return self.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_hscaiOdU2B"
      },
      "outputs": [],
      "source": [
        "class ImageCaption:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the models and processors for image captioning and VQA\"\"\"\n",
        "        # Load caption model\n",
        "        self.caption_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "        self.caption_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "        # Load VQA model\n",
        "        self.vqa_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
        "        self.vqa_model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
        "\n",
        "    def get_caption(self, image):\n",
        "        \"\"\"Generate a caption for the input image\"\"\"\n",
        "        text = \"a photo of\"\n",
        "        inputs = self.caption_processor(image, text, return_tensors=\"pt\")\n",
        "        caption = self.caption_model.generate(**inputs)\n",
        "        # Fix: Correcting processor variable reference\n",
        "        caption = self.caption_processor.decode(caption[0], skip_special_tokens=True)\n",
        "        return caption\n",
        "\n",
        "    def ask_question(self, image, question):\n",
        "        \"\"\"Answer a question related to the input image\"\"\"\n",
        "        inputs = self.vqa_processor(image, question, return_tensors=\"pt\")\n",
        "        # Fix: Use proper method for VQA (not generate)\n",
        "        output = self.vqa_model.generate(**inputs)\n",
        "        # Decoding answer using processor\n",
        "        ans = self.vqa_processor.decode(output[0], skip_special_tokens=True)\n",
        "        return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lv4F_oTdU2B"
      },
      "outputs": [],
      "source": [
        "class TextToAudio:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def get_audio(self,text,output_file_name=\"output.mp3\"):\n",
        "        try:\n",
        "            # Generate the speech using gTTS\n",
        "            tts = gTTS(text=text, lang='ar')\n",
        "\n",
        "            # Save the audio to an mp3 file\n",
        "            tts.save(output_file_name)\n",
        "\n",
        "            # Return the file path\n",
        "            return output_file_name\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating audio: {e}\")\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0seo6f_Yczt"
      },
      "outputs": [],
      "source": [
        "class QuestionGenerator:\n",
        "    def __init__(self):\n",
        "        # Set seed to 0\n",
        "        torch.random.manual_seed(0)\n",
        "        # Load model\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            \"microsoft/Phi-3.5-mini-instruct\",\n",
        "            device_map=\"cuda\",\n",
        "            torch_dtype=\"auto\",\n",
        "            trust_remote_code=True,\n",
        "        )\n",
        "        # Load Tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
        "\n",
        "    def suggest_questions(self,caption):\n",
        "        # Define system prompt and pass image caption to generate questions based on it\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a model designed to generate thoughtful and precise questions based on image captions. Your task is to generate 4 questions related to the image described by the caption. The first question should suggest a possible change to the image, which can be used as a prompt for stable diffusion to generate a new image based on image user has given. The other three questions should ask about very simple, specific details that a question-answering model can respond to in one or two words. Keep these three questions short and straightforward to avoid confusion.Output only the questions.\"},\n",
        "            {\"role\": \"user\", \"content\": \"Here is an image caption: 'A person riding a red bicycle in a busy city street.'\"},\n",
        "            {\"role\": \"assistant\", \"content\": 'Would you like to change the color of the bicycle to blue?\\n What color is the bicycle? \\n Is the person wearing a helmet? \\n How many people are visible?'\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": \"Here is an image caption: 'A dog playing in a garden with a ball.'\"},\n",
        "            {\"role\": \"assistant\", \"content\": 'Would you like to change the type of ball to a frisbee?\\n What color is the dog?\\n Are there any trees in the garden?\\n Is the dog running or standing still?'\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": f\"Here is an image caption: '{caption}'\"},\n",
        "        ]\n",
        "        # define pipeline\n",
        "        pipe = pipeline(\n",
        "            \"text-generation\",\n",
        "            model= self.model,\n",
        "            tokenizer= self.tokenizer,\n",
        "        )\n",
        "        # define generation arguments\n",
        "        generation_args = {\n",
        "            \"max_new_tokens\": 500,\n",
        "            \"return_full_text\": False,\n",
        "            \"temperature\": 0.0,\n",
        "            \"do_sample\": False,\n",
        "        }\n",
        "        # Generate the output\n",
        "        output = pipe(messages, **generation_args)\n",
        "        # return the generated questions\n",
        "        return output[0]['generated_text'].split('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yaYiTPiwRCB"
      },
      "source": [
        "# Create APP Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNRNxdkGdU2B"
      },
      "outputs": [],
      "source": [
        "class APP:\n",
        "    def __init__(self):\n",
        "        # Initialize all the required components\n",
        "        self.translator = TranslateText()\n",
        "        self.caption_model = ImageCaption()\n",
        "        self.question_generator = QuestionGenerator()\n",
        "        self.tts = TextToAudio()\n",
        "\n",
        "    def generate_caption(self, image):\n",
        "        # Step 1: Generate image caption\n",
        "        caption = self.caption_model.get_caption(image)\n",
        "\n",
        "        # Step 2: Translate caption to Arabic\n",
        "        translated_caption = self.translator.get_translation(caption, en_ar=True)\n",
        "\n",
        "        # Step 3: Generate Arabic speech from caption\n",
        "        speech = self.tts.get_audio(translated_caption[0])\n",
        "\n",
        "        # Step 4 : Generate questions from caption\n",
        "        suggested_questions = self.question_generator.suggest_questions(caption)\n",
        "\n",
        "        # Step 5: Translate suggested questions to Arabic\n",
        "        translated_questions = []\n",
        "        for question in suggested_questions:\n",
        "            translated_questions.append(self.translator.get_translation(question, en_ar=True))\n",
        "\n",
        "        return caption ,translated_caption[0], speech , translated_questions\n",
        "\n",
        "    def answer_question(self, image, question):\n",
        "        # Translate queston from Arabic to English\n",
        "        question = self.translator.get_translation(question, ar_en=True)\n",
        "\n",
        "        # Step 4: Answer the question based on the image\n",
        "        answer = self.caption_model.ask_question(image, question)\n",
        "\n",
        "        # Step 5: Translate the answer to Arabic\n",
        "        translated_answer = self.translator.get_translation(answer, en_ar=True)\n",
        "        return translated_answer[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rI2r0QFbHaL8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "0c09754b9ad24a3aa4ccfc13cbc61a4e",
            "7da1d41ad81d4e009c36f28f7061c478",
            "557847a569e6491abdae94dfab2affff",
            "2dc4b01915b341da9bead9ffcd428155",
            "3e682b98400b49ffad45778f1818dc53",
            "a24bf3bf9ff246549d7a670b9a4507ce",
            "4f6c3a5d72e84a36bab544d9bd972702",
            "b2be82975d3b42feb9d753affc2a04df",
            "4946388ed1f0427186f3601306521d8a",
            "4e208fbc60d8454c95a1391cf20e6c90",
            "a0bbb78b944b4fffbc0bf176a6c2ae5e"
          ]
        },
        "id": "O5nLqiUbdU2B",
        "outputId": "fd3ac6a3-ce21-4353-a79c-8389d232c70b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c09754b9ad24a3aa4ccfc13cbc61a4e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Instantiate the app\n",
        "app = APP()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TPrmUstyzp0"
      },
      "outputs": [],
      "source": [
        "img_url = 'https://images.unsplash.com/photo-1727774477390-2c1d534a28e2?w=500&auto=format&fit=crop&q=60&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxmZWF0dXJlZC1waG90b3MtZmVlZHwyMHx8fGVufDB8fHx8fA%3D%3D'\n",
        "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DfT68GCyvN0",
        "outputId": "f884aad5-e85d-41c9-e5d5-9060894adf04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('a photo of a woman holding an umbrella in front of a window',\n",
              " 'صورة للنساء اللاتي يحملن مظلة أمام نافذة',\n",
              " 'output.mp3',\n",
              " [['هل ترغبون في تغيير الإعداد ليوم ممطر خارج النافذة؟'],\n",
              "  ['ماذا يرتدي المرأة؟'],\n",
              "  ['هل الشظلة مفتوحة أم مغلقة؟'],\n",
              "  ['ما لون النافذة؟']])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "app.generate_caption(raw_image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app.answer_question(raw_image,\"ما هو لون بشرة الأمرأة\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "PT3kmxUGASnd",
        "outputId": "981c2353-8486-4a4d-d4bb-3f66054ab02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'أبيض'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF99YY3xwi-Y"
      },
      "source": [
        "# Create Gradio interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "fHBeoNpmdn5T",
        "outputId": "27b42dc2-5c26-43c0-964b-e6549412b4ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://76a990a77f2c68971b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://76a990a77f2c68971b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Function to generate the caption, speech, and questions\n",
        "def generate_caption(image):\n",
        "    try:\n",
        "        # Get the translated caption, speech, and suggested questions\n",
        "        caption , translated_caption, speech, suggested_questions = app.generate_caption(image)\n",
        "\n",
        "        # Clean and format questions\n",
        "        questions_cleaned = [q[0] for q in suggested_questions]  # Extract each question from the list of lists\n",
        "\n",
        "        # Ensure there are 4 questions, if less, fill with empty strings\n",
        "        while len(questions_cleaned) < 4:\n",
        "            questions_cleaned.append(\"\")  # Fill with empty strings if fewer than 4 questions\n",
        "\n",
        "        # Return caption text, audio file, and each question separately\n",
        "        return caption, translated_caption, speech, questions_cleaned[0], questions_cleaned[1], questions_cleaned[2], questions_cleaned[3]\n",
        "\n",
        "    except Exception as e:\n",
        "        # Return default values in case of error\n",
        "        return \"Error generating caption.\", None, \"Error: Couldn't generate question 1\", \"Error: Couldn't generate question 2\", \"Error: Couldn't generate question 3\", \"Error: Couldn't generate question 4\"\n",
        "\n",
        "# Function to answer the user question\n",
        "def answer_question(image, user_question):\n",
        "    try:\n",
        "        answer = app.answer_question(image, user_question)\n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Function to populate the user question textbox\n",
        "def set_user_question(question):\n",
        "    return question\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"<h1 align='center'>Image Captioning and Question Answering App (Arabic)</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        image_input = gr.Image(label=\"Upload an Image\", type=\"pil\")\n",
        "\n",
        "    with gr.Row():\n",
        "        generate_btn = gr.Button(\"Generate Caption\")\n",
        "\n",
        "    with gr.Row():\n",
        "        debug_caption = gr.Textbox(label=\"English Caption\", lines=2)\n",
        "        caption_output = gr.Textbox(label=\"Caption\", lines=2)\n",
        "        audio_output = gr.Audio(label=\"Caption Audio\")\n",
        "\n",
        "    # Create buttons for each question\n",
        "    with gr.Row():\n",
        "        question_btn1 = gr.Button(\"Suggested Question 1\")\n",
        "        question_output1 = gr.Textbox(label=\"Suggested Question\", lines=1)\n",
        "        question_btn2 = gr.Button(\"Suggested Question 2\")\n",
        "        question_output2 = gr.Textbox(label=\"Suggested Question\", lines=1)\n",
        "        question_btn3 = gr.Button(\"Suggested Question 3\")\n",
        "        question_output3 = gr.Textbox(label=\"Suggested\", lines=1)\n",
        "        question_btn4 = gr.Button(\"Suggested Question 4\")\n",
        "        question_output4 = gr.Textbox(label=\"Suggested Question\", lines=1)\n",
        "\n",
        "    with gr.Row():\n",
        "        user_question = gr.Textbox(label=\"Ask a Question (in Arabic)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        answer_btn = gr.Button(\"Get Answer\")\n",
        "\n",
        "    with gr.Row():\n",
        "        answer_output = gr.Textbox(label=\"Answer (Arabic)\", lines=2)\n",
        "\n",
        "    # Function bindings\n",
        "    generate_btn.click(\n",
        "        generate_caption,\n",
        "        inputs=[image_input],\n",
        "        outputs=[debug_caption,caption_output, audio_output, question_output1, question_output2, question_output3, question_output4]\n",
        "    )\n",
        "\n",
        "    # Set user question when a button is clicked\n",
        "    question_btn1.click(set_user_question, inputs=question_output1, outputs=user_question)\n",
        "    question_btn2.click(set_user_question, inputs=question_output2, outputs=user_question)\n",
        "    question_btn3.click(set_user_question, inputs=question_output3, outputs=user_question)\n",
        "    question_btn4.click(set_user_question, inputs=question_output4, outputs=user_question)\n",
        "\n",
        "    answer_btn.click(answer_question, inputs=[image_input, user_question], outputs=[answer_output])\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnJmkCFE1f7e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30776,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c09754b9ad24a3aa4ccfc13cbc61a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7da1d41ad81d4e009c36f28f7061c478",
              "IPY_MODEL_557847a569e6491abdae94dfab2affff",
              "IPY_MODEL_2dc4b01915b341da9bead9ffcd428155"
            ],
            "layout": "IPY_MODEL_3e682b98400b49ffad45778f1818dc53"
          }
        },
        "7da1d41ad81d4e009c36f28f7061c478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a24bf3bf9ff246549d7a670b9a4507ce",
            "placeholder": "​",
            "style": "IPY_MODEL_4f6c3a5d72e84a36bab544d9bd972702",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "557847a569e6491abdae94dfab2affff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2be82975d3b42feb9d753affc2a04df",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4946388ed1f0427186f3601306521d8a",
            "value": 2
          }
        },
        "2dc4b01915b341da9bead9ffcd428155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e208fbc60d8454c95a1391cf20e6c90",
            "placeholder": "​",
            "style": "IPY_MODEL_a0bbb78b944b4fffbc0bf176a6c2ae5e",
            "value": " 2/2 [00:39&lt;00:00, 18.59s/it]"
          }
        },
        "3e682b98400b49ffad45778f1818dc53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24bf3bf9ff246549d7a670b9a4507ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f6c3a5d72e84a36bab544d9bd972702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2be82975d3b42feb9d753affc2a04df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4946388ed1f0427186f3601306521d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e208fbc60d8454c95a1391cf20e6c90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0bbb78b944b4fffbc0bf176a6c2ae5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}